---
title: "Pesticide use near BBS transects"
author: "Tyson Wepprich"
date: "Monday, November 10, 2014"
output: html_document
---

This summarizes my process for estimating pesticide use over areas we define (instead of county-level estiamtes). 
I try to include all analyses, with eval=FALSE for ones requiring huge data files not uploaded to github.

Known issues:
1992 Landcover estimated by subtracting "changed" pixels (from the 1992-2001 retrofit product) from the 2001 Landcover.
This seemed to give reasonable extrapolations of landcover in each county over time.


```{r libraries}
# List of packages for session
.packages = c("rgdal", "raster","plyr", "dplyr", "ggplot2", "plotKML", "sp", "rgeos", "maptools", "stringr", "data.table", "snow", "readr")

# Install CRAN packages (if not already installed)
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) install.packages(.packages[!.inst])

# Load packages into session 
lapply(.packages, library, character.only = TRUE)
# lapply(.packages, library)
```

Load pesticide data (not uploaded to github) and merge all years together. Output csv of pesticide
use in OH and bordering counties. Data from USGS: http://water.usgs.gov/nawqa/pnsp/usage/maps/

Future updates:
Code it so data is downloaded directly from USGS website txt files, better for
reproducibility and file storage.

```{r load pesticide data, eval=FALSE}

setwd("C:/Users/Tyson/Desktop/Pesticides") #sorry, just makes it easier!

#Combine all downloaded USGS pesticide data
filenames <- list.files()
EPA.high <- do.call("rbind", lapply(filenames[grep("EPest.high", filenames)], read.table, header = TRUE, sep = "\t"))
EPA.low <- do.call("rbind", lapply(filenames[grep("EPest.low", filenames)], read.table, header = TRUE, sep = "\t"))

#updated 2008-12 data, replaces preliminary data, new 2015 report by Baker and Stone
setwd("C:/Users/Tyson/Desktop/Pesticides/ds907_appendix2_tables1-14")
filenames <- list.files()
EPA.high.update <- do.call("rbind", lapply(filenames[grep("high", filenames)], read.table, header = TRUE, sep = "\t"))
EPA.low.update <- do.call("rbind", lapply(filenames[grep("low", filenames)], read.table, header = TRUE, sep = "\t"))

setwd("C:/Users/Tyson/Desktop/Pesticides")
#Datasets overlap in 2008-2009, just use newer report for these years
EPA.high <- rbind(EPA.high[EPA.high$YEAR < 2008, ], EPA.high.update)
EPA.low <- rbind(EPA.low[EPA.low$YEAR < 2008, ], EPA.low.update)

#Add unique 5-digit GEOID for each county by combining state and county FIPS codes
EPA.high$GEOID <- paste(EPA.high$STATE_FIPS_CODE, formatC(EPA.high$COUNTY_FIPS_CODE, width = 3, format = "d", flag = "0"), sep = "")
EPA.low$GEOID <- paste(EPA.low$STATE_FIPS_CODE, formatC(EPA.low$COUNTY_FIPS_CODE, width = 3, format = "d", flag = "0"), sep = "")

#Subset by Ohio counties + bordering counties in other states
#Sometimes buffers around sites extend across state lines
co.shp <- "oh_counties_plus"
OHco <- readOGR(dsn = "C:/Users/Tyson/Desktop/Clipped/Final clipped", layer = co.shp)
OHplus_GEOID <- unique(as.character(OHco$GEOID))

pest.states.low <- EPA.low[which(EPA.low$GEOID %in% OHplus_GEOID), ]
pest.states.high <- EPA.high[which(EPA.high$GEOID %in% OHplus_GEOID), ]

names(pest.states.high)[5] <- "KG_EPhigh"
names(pest.states.low)[5] <- "KG_EPlow"
county.data <- merge(pest.states.high, pest.states.low, all.x = TRUE)

#######
#How often are the compounds used? Trying to reduce size.
# test <- county.data %>%
#   group_by(COMPOUND) %>%
#   summarise(yr_by_county_use = n(), 
#             total_kg = sum(KG_EPhigh),
#             years_used = length(unique(YEAR)),
#             counties_used = length(unique(GEOID)))
# 
# write.csv(test, "OH_pest_classes.csv", row.names = FALSE)

#Back to github folders, sorry for using setwd so much
setwd("C:/Users/Tyson/REPO/NCEAS-RENCI_2014")

#Using Pesticide Action Network and Alan Wood classification
#Just looks at total use by classes here

#Added classification from PAN to OH_pest_classes.csv
pest_class <- read_csv("Pesticides/PestGrouping/OH_pest_classes.csv")
pest_moa <- read_csv("Pesticides/PestGrouping/OH_pest_usage.csv")

#this file used later, I think I updated it manually in excel with a column called "TysonUseType",
#which tried to simplify uses to one per compound when obvious
pest_traits <- merge(pest_class, pest_moa, by = "COMPOUND")
# write_csv(pest_traits, "OH_pest_traits.csv")

sort_pest <- pest_traits %>%
  group_by(AlanWoodChemClass) %>%
  summarise(total_kg = sum(total_kg), numCompounds = n()) %>%
  arrange(-total_kg) %>%
  data.frame()

############
#Pest traits modified in excel to match MOA with IRAC, HRAC, and FRAC publications

pest_traits <- read.csv("Pesticides/PestGrouping/OH_pest_traits.csv")

#For now, just use pesticides with MOA information
#This removes ~80 compounds, but 95.5% total kg used have MOA information
pest_moa <- pest_traits[-which(pest_traits$MOA_source == "MISSING"), ]

#For each of 3 use types (herbicide, insecticide, fungicide), group into broad MOA
#Letters used for FRAC and HRAC, numbers for IRAC
pest_moa_irac <- pest_moa %>% filter(MOA_source == "IRAC")
pest_moa_frac <- pest_moa %>% filter(MOA_source == "FRAC")
pest_moa_hrac <- pest_moa %>% filter(MOA_source == "HRAC")

pest_moa_irac$BroadMOA <- c(unlist(strsplit(gsub("[^[:digit:] ]", "", 
                            pest_moa_irac$MOA), " +")), 
                            rep("U", length(which(pest_moa_irac$MOA == "UN"))))
pest_moa_irac$MOAuse <- paste("ins", pest_moa_irac$BroadMOA, sep = "_")

pest_moa_frac$BroadMOA <- unlist(strsplit(gsub("[^[:alpha:] ]", "", pest_moa_frac$MOA), " +"))
pest_moa_frac$BroadMOA <- mapvalues(pest_moa_frac$BroadMOA, from = c("Multisite", "UN"), to = c("M", "U"))
pest_moa_frac$MOAuse <- paste("fun", pest_moa_frac$BroadMOA, sep = "_")


pest_moa_hrac$BroadMOA <- unlist(strsplit(gsub("[^[:alpha:] ]", "", pest_moa_hrac$MOA), " +"))
pest_moa_hrac <- pest_moa_hrac %>% filter(BroadMOA != "CF") #remove one minor multiMOA compound
pest_moa_hrac$MOAuse <- paste("her", pest_moa_hrac$BroadMOA, sep = "_")

pest_moa <- rbind(pest_moa_irac, pest_moa_hrac, pest_moa_frac)
write.csv(pest_moa, "Pesticides/PestGrouping/OHpest_traits_allRACs.csv", row.names = FALSE)

#######

pesticides <- merge(county.data, pest_moa[, c("COMPOUND", "TysonUseType", "MOAuse")])

# write.csv(temp2, file = "../../REPO/NCEAS-RENCI_2014/Pesticides/OHpesticides.csv", row.names = FALSE)
write.csv(pesticides, file = "Pesticides/OHpesticidesMOA.csv", row.names = FALSE)

```

Extract landcover for each county from 4 rasters from the NLCD products. The raw rasters were clipped in QGIS, see readme.
GIS data not uploaded to Github because it's big. 

```{r extract landcover for each county, eval=FALSE}
setwd("C:/Users/Tyson/Desktop/Clipped/Final clipped")

#################
#2006 Landcover
#################
test.file <- "lc2006.tif"
r <- raster(test.file)

#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

#bring in county shapefile and reproject to match rasters
co.shp <- "oh_counties_plus"
OHco <- readOGR(dsn = getwd(), layer = co.shp)
OHco_p <- reproject(OHco, proj4string(r))

#Function to extract land use pixels from raster by county GEOID
### Make function and try it out before parallelizing
    RasterToCounty <- function(GEOID){
      co_sub <- OHco_p[OHco_p$GEOID == GEOID, ]
      co_lc <- extract(r, co_sub)
      counts <- lapply(co_lc, table)
      #pct <- lapply(counts, FUN=function(x){x / sum(x)})
      return(list(GEOID, counts))
    }
    #test <- lapply(unique(OHco_p$GEOID)[1:2], RasterToCounty)

#Runtime 1.75 hours
system.time({
    ### set up cluster call
    cl <- makePSOCKcluster(4)

    clusterExport(cl, c("OHco_p", "RasterToCounty", "r"))
    junk <- clusterEvalQ(cl, c(library(raster), library(rgdal)))

    ### read into raster format using parallel version of lapply
    results.par <- parLapply(cl, unique(OHco_p$GEOID), RasterToCounty)

    stopCluster(cl)
})

save(results.par, file = "lc_OH2006.RData") 


######################
#2001 landcover
######################
test.file <- "lc2001.tif"
r <- raster(test.file)

#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

#Runtime 1.75 hours
system.time({
    ### set up cluster call
    cl <- makePSOCKcluster(4)

    clusterExport(cl, c("OHco_p", "RasterToCounty", "r"))
    junk <- clusterEvalQ(cl, c(library(raster), library(rgdal)))

    ### read into raster format using parallel version of lapply
    results.par <- parLapply(cl, unique(OHco_p$GEOID), RasterToCounty)

    ### stop the cluster
    stopCluster(cl)
})

save(results.par, file = "lc_OH2001.RData") 

##################
#2011 landcover
######################
test.file <- "lc2011.tif"
r <- raster(test.file)

#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

#Runtime 1.75 hours
system.time({
    ### set up cluster call
    cl <- makePSOCKcluster(4)

    clusterExport(cl, c("OHco_p", "RasterToCounty", "r"))
    junk <- clusterEvalQ(cl, c(library(raster), library(rgdal)))

    ### read into raster format using parallel version of lapply
    results.par <- parLapply(cl, unique(OHco_p$GEOID), RasterToCounty)

    ### stop the cluster
    stopCluster(cl)
})

save(results.par, file = "lc_OH2011.RData") 



##################
#Change from 1992 to 2001 landcover
######################

test.file <- "lc_chg_9201.tif"
r <- raster(test.file)

#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

#Runtime 1.75 hours
system.time({
    ### set up cluster call
    cl <- makePSOCKcluster(4)

    clusterExport(cl, c("OHco_p", "RasterToCounty", "r"))
    junk <- clusterEvalQ(cl, c(library(raster), library(rgdal)))

    ### read into raster format using parallel version of lapply
    results.par <- parLapply(cl, unique(OHco_p$GEOID), RasterToCounty)

    ### stop the cluster
    stopCluster(cl)
})

save(results.par, file = "lc_chg_9201.RData") 
```

This chunk takes landcover by county data from the 4 rasters, and groups them together
by simplified ALI land-use codes.

I also tried to figure out whether the 1992 to 2001 change product could be used 
to estimate landcover in the 90s. There were weird things happening, like the number of pixels 
total per county changes between 1992 and 2001. I think this is unavoidable and
makes a tiny difference. USGS will be correcting these for 2016 update I think.


```{r landcover over time, eval=FALSE}

setwd("C:/Users/Tyson/REPO/NCEAS-RENCI_2014")

load(file = "Landcover/lc_chg_9201.RData")
lc_chg90s <- results.par
load(file = "Landcover/lc_OH2011.RData")
lc_2011 <- results.par
load(file = "Landcover/lc_OH2006.RData")
lc_2006 <- results.par
load(file = "Landcover/lc_OH2001.RData")
lc_2001 <- results.par
rm(results.par)

#One issue is that landcover classification is different in 1992. The change product allows comparison
#BUT, only more general Anderson Level I classification (7 classes) will be used
ALIclass <- read.csv("Landcover/nlcd_class9201.csv", header = TRUE)

#Landcover classes by county were extracted from raster and put into lists
#This function takes the messy lists and converts into usable data.frame
CountyPixels <- function(lc){
  results <- lc
  lc_long <- data.frame()
  for (i in 1:length(results)){
    GEOID <- unlist(results[[i]][1])
    Pixels <- as.numeric(unlist(results[[i]][2]))
    Class <- names(unlist(results[[i]][2]))
    temp <- data.frame(GEOID, Pixels, Class)
    lc_long <- rbind(lc_long, temp)
    }
  return(lc_long)
}

pix_2001 <- CountyPixels(lc_2001)
pix_2006 <- CountyPixels(lc_2006)
pix_2011 <- CountyPixels(lc_2011)
pix_chg90s <- CountyPixels(lc_chg90s)

#one issue is that the number of pixels per county is slightly off between 1992 and 2001, unknown why.
#In same projection, but maybe paths of satellites different. Generally <100 pixels = 0.09 km2

#translation table for 2001, 2006, 2011 ALII codes back to ALI codes
landclass <- data.frame(Value = c(0, 11, 21, 22, 23, 24, 31, 41, 42, 43, 52, 71, 81, 82, 90, 95), Class = c("NoData", "Water", "Urban", "Urban", "Urban", "Urban", "Barren", "Forest", "Forest", "Forest", "Grass", "Grass", "Agri", "Agri", "Wet", "Wet"), ALIcode = c(0, 1, 2, 2, 2, 2, 3, 4, 4, 4, 5, 5, 6, 6, 7, 7))


#these give Anderson Level I classes (total pixels) for each county
lc_county_2001 <- pix_2001 %>% 
  group_by(GEOID) %>% 
  mutate(reclass = mapvalues(Class, from = landclass$Value, to = landclass$ALIcode)) %>% 
  group_by(GEOID, reclass) %>% 
  summarise(total = sum(Pixels)) %>% data.frame()

lc_county_2006 <- pix_2006 %>% 
  group_by(GEOID) %>% 
  mutate(reclass = mapvalues(Class, from = landclass$Value, to = landclass$ALIcode)) %>% 
  group_by(GEOID, reclass) %>% 
  summarise(total = sum(Pixels)) %>% data.frame()

lc_county_2011 <- pix_2011 %>% 
  group_by(GEOID) %>% 
  mutate(reclass = mapvalues(Class, from = landclass$Value, to = landclass$ALIcode)) %>% 
  group_by(GEOID, reclass) %>% 
  summarise(total = sum(Pixels)) %>% data.frame()

#Assign 1992 and 2001 land cover from the NLCD change product
#it will be approximate
#changed pixels given 2 digit classes, first digit is from 1992, second digit from 2011
#These two lines separate the 2 digit class
pix_chg90s$reclass92 <- sapply(as.character(pix_chg90s$Class), substring, 1, 1)
pix_chg90s$reclass01 <- sapply(formatC(as.character(pix_chg90s$Class), width = 2, format = "d", flag = "0"), substring, 2, 2)

lc_county_1992_est <- pix_chg90s %>%
  group_by(GEOID, reclass92) %>%
  summarise(total = sum(Pixels)) %>% data.frame()

lc_county_2001_est <- pix_chg90s %>%
  group_by(GEOID, reclass01) %>%
  summarise(total = sum(Pixels)) %>% data.frame()

#compare 2001 estimates for fun
#estimates are pretty darn close, from now on, just will use 1992 land cover from chg layer
#however, 1992 estimates really don't fit the 2001-2011 trends. Not comparable according to NLCD
names(lc_county_2001_est)[2] <- "reclass"
names(lc_county_1992_est)[2] <- "reclass"
lc_compare <- merge(lc_county_2001, lc_county_2001_est, by = c("GEOID", "reclass"))

a <- ggplot(lc_compare, aes(x = total.x, y = total.y)) + geom_point()
a + facet_wrap(~reclass, scales = "free") + geom_abline(intercept = 0, slope = 1)

#Try estimating 1992 LC based on change from 2001 Landcover, instead of using 1992 estimates as the base
pix_chg90s$Class <- as.numeric(as.character(pix_chg90s$Class))
chg90s_1 <- pix_chg90s %>% filter(Class > 9) %>% group_by(GEOID, reclass92) %>% summarise(add_to_2001 = sum(Pixels)) 
chg90s_2 <- pix_chg90s %>% filter(Class > 9) %>% group_by(GEOID, reclass01) %>% summarise(sub_from_2001 = sum(Pixels))
names(chg90s_1)[2] <- "reclass"
names(chg90s_2)[2] <- "reclass"

chg90s <- merge(chg90s_1, chg90s_2, by = c("GEOID", "reclass"), all = TRUE)
chg90s_2001 <- merge(lc_county_2001, chg90s)
chg90s_2001$sub_from_2001 <- chg90s_2001$sub_from_2001 * -1
chg90s_2001$total_92est <- rowSums(chg90s_2001[, c("total", "add_to_2001", "sub_from_2001")], na.rm = TRUE)
lc_county_1992_backest <- chg90s_2001[, c("GEOID", "reclass", "total_92est")]
names(lc_county_1992_backest)[3] <- "total"
lc_county_1992_backest$year <- 1992

#This plots different estimates for 1992 to compare, pretty close
# lc_compare_1992 <- merge(lc_county_1992_est, lc_county_1992_backest, by = c("GEOID", "reclass"))
# 
# a <- ggplot(lc_compare_1992, aes(x = total.x, y = total.y)) + geom_point()
# a + facet_wrap(~reclass, scales = "free") + geom_abline(intercept = 0, slope = 1)

#bring all estimates together in one data frame
lc_county_2001$year <- 2001
lc_county_2006$year <- 2006
lc_county_2011$year <- 2011
lc_county_1992_est$year <- 1992
lc_county_2001_est$year <- 2001

#####This code was used for plotting estimates of landcover by county x LC class to see which estimates for 1992 were more wrong.
# 
#for plotting
# lc_county_2001$col <- "A"
# lc_county_2006$col <- "A"
# lc_county_2011$col <- "A"
# lc_county_1992_est$col <- "B"
# lc_county_1992_backest$col <- "A"
# lc_county_2001_est$col  <-  "B"
# # 
# # 
# lc_all <- rbind(lc_county_1992_est, lc_county_1992_backest, lc_county_2001, lc_county_2001_est, lc_county_2006, lc_county_2011)
# 
# # #plots trends over time by landclass for a county
# # #This shows that 1992 landcover seems to be misclassifying things. Overestimating forests but underestimating others.
#  library(splines)
#  library(MASS)
#  b <- ggplot(lc_all[lc_all$GEOID == "39161",], aes(x = year, y = total, group = GEOID)) + geom_point(aes(colour = factor(col)))
#  b + facet_wrap(~reclass, scales = "free") + geom_smooth(method = "lm", formula = y ~ ns(x,2))
# 


#CONCLUSION
#Will use 1992 estimate of landcover based on 2001 values with 1992/2001 change product pixels
#the 1992 estimates based on 1992 classes are farther off
lc_all <- rbind(lc_county_1992_backest, lc_county_2001, lc_county_2006, lc_county_2011)
lc_all <- lc_all[, -5]
lc_all <- data.table(lc_all)

#expand lc_all so that all reclass values included, 0 if missing
test <- CJ(unique(lc_all[,GEOID]), unique(lc_all[,reclass]), unique(lc_all[,year]), sorted = FALSE)
setnames(test, "V1", "GEOID")
setnames(test, "V2", "reclass")
setnames(test, "V3", "year")

test2 <- merge(lc_all, test, by = c("reclass", "year", "GEOID"), all = TRUE)
test2$total[is.na(test2$total) == TRUE] <- 0
test2 <- test2[-which(test2$reclass == 0), ]

#This just gives landcover classes by county for years of USGS raster products
write.csv(test2, file = "C:/Users/Tyson/REPO/NCEAS-RENCI_2014/Landcover/landcover_all.csv", row.names = FALSE)

```

Take landcover estimates by county and make yearly estimates based connecting the 4 data points(1992, 2001, 2006, 2011).
Then scale county-level pesticide use by the amount of agricultural land use in all years.
Final output has kg of compound per square kilometer of agricultural land use for each county x year x Mode of action group.

Also, data.table is fucking amazing.

```{r landcover by year, eval = FALSE}
setwd("C:/Users/Tyson/REPO/NCEAS-RENCI_2014")

# pests <- read.csv("Pesticides/OHpesticides.csv", header = TRUE)
# lc_all <- read.csv("landcover_all.csv", header = TRUE)

pests <- fread("Pesticides/OHpesticidesMOA.csv", header = TRUE)
lc_all <- fread("Landcover/landcover_all.csv", header = TRUE)

#UPDATE: not doing regression to extrapolate land cover pixels over time
#just going to draw a line connecting the 4 dots and adding a 2012 estimate
LandcoverLine <- function(dat){
  yr <- data.frame(year = c(1992:2012))
  obs <- sort(dat$year)
  test <- data.frame()
  for (i in 1:(length(obs) - 1)){
    pix.seq <- seq(from = dat$total[dat$year == obs[i]], 
                   to = dat$total[dat$year == obs[i + 1]], 
                   len = (obs[i + 1] - obs[i] + 1))
    yr.seq <- seq(from = obs[i], to = obs[i+1])
    test <- rbind(test, data.frame(year = yr.seq, pix = pix.seq))
    }
  out <- test[-which(duplicated(test)), ]
  out <- merge(yr, out, all.x = TRUE)
  out$pix[out$year == 2012] <- out$pix[out$year == 2011] + (out$pix[out$year == 2011] - out$pix[out$year == 2010])
  return(out)
  }

setkey(lc_all, GEOID)
lc_all[, total:=as.numeric(total)]

test <- lc_all[,LandcoverLine(data.frame(year = year, total = total)),by = list(GEOID, reclass)]
setnames(test,"year","YEAR")
write.csv(test, file = "Landcover/LC_county_overtime.csv")

lc_ag <- test[reclass == 6]
setkey(lc_ag, GEOID, YEAR)

#Join agriculture landcover area to pesticide data
#Export county's pesticide use rate by km2 of agricultural land use.
##################
#Updated
#PESTICIDE MOA INSTEAD OF COMPOUND
pests <- pests[, list(KGbyMOA = sum(KG_EPhigh)), by = list(YEAR, GEOID, MOAuse)]

setkey(pests, GEOID, YEAR)
pest_county <- lc_ag[pests]
# pest_county[,`:=`(high_kg_km2ag = KG_EPhigh / (pix * 0.0009), low_kg_km2ag = KG_EPlow / (pix * 0.0009)) ]
pest_county[,`:=`(high_kg_km2ag = KGbyMOA / (pix * 0.0009))]


# pest_export <- pest_county[, c("GEOID", "YEAR", "pix", "COMPOUND", "high_kg_km2ag", "low_kg_km2ag"), with = FALSE]
pest_export <- pest_county[, c("GEOID", "YEAR", "pix", "MOAuse", "KGbyMOA", "high_kg_km2ag"), with = FALSE]

# write.csv(pest_export, file = "Pesticides/estimated_pesticides_OHcounty.csv", row.names = FALSE)
write.csv(pest_export, file = "Pesticides/estimated_pesticides_OHcounty_MOA.csv", row.names = FALSE)

```


Thought new BBS route shapefile had additional data that we missed, 
BUT
the fifty stop raw bird count data doesn't have any of the new routes, so I think we are fine.

```{r, eval = FALSE}
bbs <- fread('BBS_data/fifty7_withRTENO.csv')
bbs_OH <- bbs[RTENO >= 66000][RTENO <= 67000]

#Changed .kml to shapefile in QGIS, but attributes locked up in xml format
bbs.shp <- "BBSroutes_newer"
bbs.rtes <- readOGR(dsn = "GIS", layer = bbs.shp)

library(stringr)
library(PBSmapping)
#extract RTENO from xml mess
bbs.rtes@data$RTENO <- str_extract(bbs.rtes@data$Descriptio, "(?<=rteno = ).*?(?=<)")
bbs.rtes@data$Descriptio <- NULL

#OH only
#problem with duplicate RTENO, routes split into segments!
test <- bbs.rtes[bbs.rtes$RTENO >= 66000 & bbs.rtes$RTENO <= 67000, ]

#nothing really merges disjoint line segments, which is what I need
#leave as is and hope buffering deals with it OK
```


Do landcover change analysis (as done for counties) only now applied to 
buffers (different radii) around BBS transects. 

```{r landcover change in BBS routes, eval=FALSE}

###############
#2006 Landcover and pesticides by BBS buffer
###############
#landcover raster
test.file <- "C:/Users/Tyson/Desktop/Clipped/Final clipped/lc2006.tif"
r <- raster(test.file)
#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

#counties shapefile
co.shp <- "oh_counties_plus"
OHco <- readOGR(dsn = "C:/Users/Tyson/Desktop/Clipped/Final clipped", layer = co.shp)
#OHco_p <- reproject(OHco, proj4string(r))
OHco_p <- spTransform(OHco, CRSobj = CRS(proj4string(r)))
OHco_p$GEOID <- as.numeric(as.character(OHco_p$GEOID))

#Import BBS routes shapefile, obtained from DataBasin
#These are the 1998 active routes, need to see how well they match up with routes used for population estimates
bbs.shp <- "bbsrtsl020Copy"
bbs_routes <- readOGR(dsn = "GIS", layer = bbs.shp)
# proj4string(bbs_routes) <- CRS("+init=epsg:5070")
bbs_routes_p <- reproject(bbs_routes, proj4string(r))

#RTENO: The route number consists of the 1- or 2-digit State ID code followed by the 3-digit route ID.
bbs_OH <- bbs_routes_p[which(bbs_routes_p$RTENO >= 66000 & bbs_routes_p$RTENO <=67000), ]

#Make GIS files for polygon buffers around the transect lines
bbs_buff_200 <- gBuffer(bbs_OH, byid = TRUE, id = NULL, width = 200, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
bbs_buff_400 <- gBuffer(bbs_OH, byid = TRUE, id = NULL, width = 400, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
bbs_buff_1000 <- gBuffer(bbs_OH, byid = TRUE, id = NULL, width = 1000, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
bbs_buff_2000 <- gBuffer(bbs_OH, byid = TRUE, id = NULL, width = 2000, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
bbs_buff_5000 <- gBuffer(bbs_OH, byid = TRUE, id = NULL, width = 5000, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
bbs_buff_10000 <- gBuffer(bbs_OH, byid = TRUE, id = NULL, width = 10000, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")

#This function extracts landcover for the county x bbs route intersections
#These can then by combined to get landcover by bbs route (with calculations of county-level pesticides added)

#ISSUE fixed: gIntersects/gIntersection use row.names as ID, but they start with 0!
ApportionLandcover <- function(counties, buffer, landcover){
  #find counties that intersect buffers, only use them for following analysis to speed things up
  bounds.sub <- gIntersects(counties, buffer, byid = TRUE)
  bounds.sub2 <- apply(bounds.sub, 2, function(x) {sum(x)})
  bounds.sub3 <- counties[which(bounds.sub2 > 0), ]
  
  #data.frame of intersections of buffers/counties
  int <- gIntersection(bounds.sub3, buffer, byid=TRUE) 
  intdf <- data.frame(intname=names(int))
  intdf$intname <- as.character(intdf$intname)
  splitid <- strsplit(intdf$intname, " ", fixed=TRUE) # split the names
  splitid <- do.call("rbind", splitid) # rbind those back together
  colnames(splitid) <- c("CountyRow", "bbsrts")
  intdf <- data.frame(intdf, splitid)
  intdf$CountyRow <- as.character(intdf$CountyRow)
  intdf$bbsrts <- as.character(intdf$bbsrts)
  
  library(snow)
  require(parallel)
  beginCluster( detectCores()-1 )
  
  lc <- extract(r, int)
  counts <- lapply(lc, table)
  out <- list(counts)
  
  endCluster()
  
 lc_out <- data.frame()
  for (j in 1:length(out[[1]])){
    temp <- out[[1]][[j]]
    temp.df <- data.frame(lc_class = names(unlist(temp)), pixels = as.numeric(unlist(temp)))
    temp.df$BBS_route <- intdf$bbsrts[j]
    temp.df$CountyRow <- intdf$CountyRow[j]
    lc_out <- rbind(lc_out, temp.df)
  }
    
 lc_out$GEOID <- mapvalues(lc_out$CountyRow, from = c(0:(length(counties)-1)), to = counties$GEOID)
 lc_out$RTENO <- mapvalues(lc_out$BBS_route, from = row.names(buffer), to = buffer$RTENO)
 return(lc_out)
}





buffers <- list(bbs_buff_200, bbs_buff_400, bbs_buff_1000, bbs_buff_2000, bbs_buff_5000, bbs_buff_10000)
buffer_LC2006 <- data.frame()
for (i in 1:length(buffers)) {
  temp <- ApportionLandcover(OHco_p, buffers[[i]], r)
  temp$buffer <- c(200, 400, 1000, 2000, 5000, 10000)[i]
  buffer_LC2006 <- rbind(buffer_LC2006, temp)
}
buffer_LC2006$year <- 2006
save(buffer_LC2006, file = "Landcover/buffer_LC2006.RData") 


###############
#2001 Landcover and pesticides by BBS buffer
###############
#landcover raster
test.file <- "C:/Users/Tyson/Desktop/Clipped/Final clipped/lc2001.tif"
r <- raster(test.file)
#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

buffers <- list(bbs_buff_200, bbs_buff_400, bbs_buff_1000, bbs_buff_2000, bbs_buff_5000, bbs_buff_10000)
buffer_LC2001 <- data.frame()
for (i in 1:length(buffers)) {
  temp <- ApportionLandcover(OHco_p, buffers[[i]], r)
  temp$buffer <- c(200, 400, 1000, 2000, 5000, 10000)[i]
  buffer_LC2001 <- rbind(buffer_LC2001, temp)
}
buffer_LC2001$year <- 2001
save(buffer_LC2001, file = "Landcover/buffer_LC2001.RData") 


###############
#2011 Landcover and pesticides by BBS buffer
###############
#landcover raster
test.file <- "C:/Users/Tyson/Desktop/Clipped/Final clipped/lc2011.tif"
r <- raster(test.file)
#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

buffers <- list(bbs_buff_200, bbs_buff_400, bbs_buff_1000, bbs_buff_2000, bbs_buff_5000, bbs_buff_10000)
buffer_LC2011 <- data.frame()
for (i in 1:length(buffers)) {
  temp <- ApportionLandcover(OHco_p, buffers[[i]], r)
  temp$buffer <- c(200, 400, 1000, 2000, 5000, 10000)[i]
  buffer_LC2011 <- rbind(buffer_LC2011, temp)
}

buffer_LC2011$year <- 2011
save(buffer_LC2011, file = "Landcover/buffer_LC2011.RData") 


###############
#1992/2001 Landcover change and pesticides by BBS buffer
###############
#landcover raster
test.file <- "C:/Users/Tyson/Desktop/Clipped/Final clipped/lc_chg_9201.tif"
r <- raster(test.file)
#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

buffers <- list(bbs_buff_200, bbs_buff_400, bbs_buff_1000, bbs_buff_2000, bbs_buff_5000, bbs_buff_10000)
buffer_LC1992 <- data.frame()
for (i in 1:length(buffers)) {
  temp <- ApportionLandcover(OHco_p, buffers[[i]], r)
  temp$buffer <- c(200, 400, 1000, 2000, 5000, 10000)[i]
  buffer_LC1992 <- rbind(buffer_LC1992, temp)
}

buffer_LC1992$year <- 1992
save(buffer_LC1992, file = "Landcover/buffer_LC1992.RData") 

#Now reclassify landcover so all years use ALI codes 
load("Landcover/buffer_LC1992.RData")
load("Landcover/buffer_LC2011.RData") 
load("Landcover/buffer_LC2001.RData") 
load("Landcover/buffer_LC2006.RData") 

#Are buffers same size over year? YES, before reclassifying to ALI
# b92 <- data.table(buffer_LC1992)
# setkey(b92, GEOID, BBS_route)
# buf92 <- b92[, sum(pixels), by = list(BBS_route, GEOID, buffer)]
# 
# b01 <- data.table(buffer_LC2001)
# setkey(b01, GEOID, BBS_route)
# buf01 <- b01[, sum(pixels), by = list(BBS_route, GEOID, buffer)]
# 
# a <- buf92[,V1, with = TRUE] - buf01[,V1,with = TRUE]

#translation table for 2001, 2006, 2011 ALII codes back to ALI codes
landclass <- data.frame(Value = c(0, 11, 21, 22, 23, 24, 31, 41, 42, 43, 52, 71, 81, 82, 90, 95), Class = c("NoData", "Water", "Urban", "Urban", "Urban", "Urban", "Barren", "Forest", "Forest", "Forest", "Grass", "Grass", "Agri", "Agri", "Wet", "Wet"), ALIcode = c(0, 1, 2, 2, 2, 2, 3, 4, 4, 4, 5, 5, 6, 6, 7, 7))

###CHANGE THESE TO USE RTENO INSTEAD OF BBS_ROUTE
#these give Anderson Level I classes (total pixels) for each county x RTENO intersection
lc_buffer_2001 <- buffer_LC2001 %>% 
  mutate(reclass = mapvalues(lc_class, from = landclass$Value, to = landclass$ALIcode)) %>% 
  group_by(RTENO, GEOID, buffer, reclass) %>% 
  summarise(total = sum(pixels))

lc_buffer_2006 <- buffer_LC2006 %>% 
  mutate(reclass = mapvalues(lc_class, from = landclass$Value, to = landclass$ALIcode)) %>% 
  group_by(RTENO, GEOID, buffer, reclass) %>% 
  summarise(total = sum(pixels)) 

lc_buffer_2011 <- buffer_LC2011 %>% 
  mutate(reclass = mapvalues(lc_class, from = landclass$Value, to = landclass$ALIcode)) %>% 
  group_by(RTENO, GEOID, buffer, reclass) %>% 
  summarise(total = sum(pixels))


#make function to define 1992 and 2001 land cover from the NLCD change product
#it will be approximate
buffer_LC1992$reclass92 <- sapply(as.character(buffer_LC1992$lc_class), substring, 1, 1)
buffer_LC1992$reclass01 <- sapply(formatC(as.character(buffer_LC1992$lc_class), width = 2, format = "d", flag = "0"), substring, 2, 2)

#Estimate 1992 LC based on change from 2001 Landcover, instead of using 1992 estimates as the base
buffer_LC1992$lc_class <- as.numeric(as.character(buffer_LC1992$lc_class))
chg90s_1 <- buffer_LC1992 %>% filter(lc_class > 9) %>% group_by(RTENO, GEOID, buffer, reclass92) %>% summarise(add_to_2001 = sum(pixels)) 
chg90s_2 <- buffer_LC1992 %>% filter(lc_class > 9) %>% group_by(RTENO, GEOID, buffer, reclass01) %>% summarise(sub_from_2001 = sum(pixels))
names(chg90s_1)[4] <- "reclass"
names(chg90s_2)[4] <- "reclass"

chg90s <- merge(chg90s_1, chg90s_2, by = c("RTENO", "GEOID", "buffer", "reclass"), all = TRUE)
chg90s_2001 <- merge(lc_buffer_2001, chg90s)
chg90s_2001$sub_from_2001 <- chg90s_2001$sub_from_2001 * -1
chg90s_2001$total_92est <- rowSums(chg90s_2001[, c("total", "add_to_2001", "sub_from_2001")], na.rm = TRUE)
lc_buffer_1992_backest <- chg90s_2001[, c("GEOID", "reclass", "RTENO", "buffer", "total_92est")]
names(lc_buffer_1992_backest)[5] <- "total"
lc_buffer_1992_backest$year <- 1992


#bring all estimates together in one data frame
lc_buffer_2001$year <- 2001
lc_buffer_2006$year <- 2006
lc_buffer_2011$year <- 2011


#CONCLUSION
#Will use 1992 estimate of landcover based on 2001 values with 1992/2001 change product pixels
#the 1992 estimates based on 1992 classes are farther off
lc_all_buffers <- rbind(lc_buffer_1992_backest, lc_buffer_2001, lc_buffer_2006, lc_buffer_2011)
lc_all_buffers <- data.table(lc_all_buffers)

#expand lc_all so that all reclass values included, 0 if missing
uniqrow <- unique(lc_all_buffers[, list(GEOID, RTENO, year)])
test <- CJ(unique(lc_all_buffers[,reclass]), unique(lc_all_buffers[,year]), unique(lc_all_buffers[, buffer]), sorted = FALSE)
setnames(test, "V1", "reclass")
setnames(test, "V2", "year")
setnames(test, "V3", "buffer")

test2 <- merge(uniqrow, test, by = "year", all = TRUE, allow.cartesian = TRUE)

test3 <- merge(lc_all_buffers, test2, by = c("reclass", "year", "GEOID", "RTENO", "buffer"), all = TRUE)
test3$total[is.na(test3$total) == TRUE] <- 0

#Intermediate product, landcover by intersection of counties and buffers
write.csv(test3, file = "Landcover/landcover_buffers.csv", row.names = FALSE)


```

Estimate landcover change over time for each BBS route x buffer x county combination.

```{r LC by buffer over time, eval = FALSE}

LandcoverLine <- function(dat){
  yr <- data.frame(year = c(1992:2012))
  obs <- sort(dat$year)
  test <- data.frame()
  for (i in 1:(length(obs) - 1)){
    pix.seq <- seq(from = dat$total[dat$year == obs[i]], 
                   to = dat$total[dat$year == obs[i + 1]], 
                   len = (obs[i + 1] - obs[i] + 1))
    yr.seq <- seq(from = obs[i], to = obs[i+1])
    test <- rbind(test, data.frame(year = yr.seq, pix = pix.seq))
    }
  out <- test[-which(duplicated(test)), ]
  out <- merge(yr, out, all.x = TRUE)
  out$pix[out$year == 2012] <- out$pix[out$year == 2011] + (out$pix[out$year == 2011] - out$pix[out$year == 2010])
  return(out)
  }




DT <- fread("Landcover/landcover_buffers.csv")
DT[, buffer:=as.character(buffer)]
DT[, total:=as.numeric(total)]
DT[, year:=as.numeric(year)]

#find landcover class pixels over time for all buffer x county intersections
setkey(DT, GEOID, RTENO)
lc_int_overtime <- DT[, LandcoverLine(data.frame(year = year, total = total)), by = list(RTENO, GEOID, reclass, buffer)]
setnames(lc_int_overtime,"year","YEAR")
setkey(lc_int_overtime, RTENO, YEAR)

# for some reason, data.table not collasping in same way as summarise in dplyr
lc_buff_overtime <- lc_int_overtime[, sum(pix, na.rm = TRUE), by = list(RTENO, reclass, buffer, YEAR)]
setnames(lc_buff_overtime, "V1", "total_pix")
lc_buff_overtime[, km2 := total_pix * 0.0009]

Class = c("NoData", "Water", "Urban", "Barren", "Forest", "Grass", "Agri", "Wetlands")
ALIcode = as.character(c(0:7))

lc_buff_overtime %>% 
  mutate(landclass = mapvalues(reclass, from = ALIcode, to = Class))

write.csv(lc_buff_overtime, file = "Landcover/LC_buffers_overtime.csv", row.names = FALSE)


#join pesticides with above data.table to get pesticide use in counties, then aggregate by buffers
#TRYING WITH MOA GROUPING
# pest <- fread("C:/Users/Tyson/REPO/NCEAS-RENCI_2014/Pesticides/estimated_pesticides_OHcounty.csv", header = TRUE)
pest <- fread("C:/Users/Tyson/REPO/NCEAS-RENCI_2014/Pesticides/estimated_pesticides_OHcounty_MOA.csv", header = TRUE)

setkey(pest, GEOID, YEAR)
pest[,pix := NULL]

lc.j <- lc_int_overtime[reclass == 6]
setkey(lc.j, GEOID, YEAR)
lc <- lc.j[pix > 0]

#fixing agri. pix problems here, total area of agri. in each buffer across counties
#this will be used to divide total pesticide use aggregated across county x buffer intersections
lc.fix <- lc %>%
  group_by(YEAR, RTENO, buffer) %>%
  mutate(ag_km2_buffer = sum(pix) * 0.0009)

pest_buff <- merge(lc.fix, pest, allow.cartesian = TRUE)
pest_buff[, kg_buffGEOID_int := pix * 0.0009 * high_kg_km2ag] #kilograms of the pesticide group in buffer x county intersection

pest_buff1 <- pest_buff %>%
  group_by(YEAR, RTENO, buffer, MOAuse, ag_km2_buffer) %>%
  summarise(kg_buff = sum(kg_buffGEOID_int)) %>%
  mutate(meanbuff_kgkm2ag = kg_buff / ag_km2_buffer)

write.csv(pest_buff1, "Pesticides/pest_buff_overtime_MOA.csv", row.names = FALSE)

# write.csv(pest_buff1, "Pesticides/pest_buff_overtime.csv", row.names = FALSE)

#This sees if the buffer areas are consistent across years
#There is a gain of total pixels between the 90s and 2001, probably due to the NLCD products
#Should investigate this more, but percentages of LC over time are probably OK to use for now
testbuff <- lc_buff_overtime %>%
  group_by(RTENO, YEAR, buffer) %>%
  summarise(size = sum(total_pix, na.rm = TRUE)) %>%
  data.frame()

#plot some pesticide class use rate changes over time
pest_buff1[, use := tstrsplit(MOAuse, "_", fixed = TRUE)[[1]]]

pestPlot <- pest_buff1 %>%
  filter(buffer == 5000) %>%
  group_by(MOAuse, YEAR, use) %>%
  summarise(meanRate = mean(meanbuff_kgkm2ag))

a <- ggplot(data = pestPlot[use == "ins"][MOAuse != "ins_1"], aes(x = YEAR, y = meanRate, group = MOAuse, color = MOAuse)) + 
  geom_line() #+ facet_grid(use ~ ., scales = "free_y")
a + theme_bw() + geom_text(data = pestPlot[YEAR == 2011][use == "ins"][MOAuse != "ins_1"], aes(label = MOAuse), hjust = 0, vjust = 0)

```

Added 16/12/14: Update BBS route coding to match population data everyone is using.
The RouteDataID is a unique identifier of site x year x other shit, but it's not used in all of USGS's data. 
Also, my landcover and pesticide .csv files use a different identifier.
I'm adding an identifier so that all can be merged: "RTENO"

```{r update BBS route coding, eval = FALSE}
library(plyr)
setwd("C:/Users/Tyson/REPO/NCEAS-RENCI_2014")

load("Pesticides/BBSrtcodes.RData")
match_file <- rts[, c(1:2)]

#Population data that we all use?
ohio_BBS <- read.csv("BBS_data/raw_data/fifty7.csv")
head(ohio_BBS)

ohio_BBS$RTENO <- paste(ohio_BBS$statenum, formatC(ohio_BBS$Route, width = 3, format = "d", flag = "0"), sep = "")

write.csv(ohio_BBS, file = "BBS_data/fifty7_withRTENO.csv", row.names = FALSE)

# NO LONGER NEEDED, HAS RTENO ALREADY
# 
# #change codes on pest_buff_overtime.csv
# pest <- read.csv("Pesticides/pest_buff_overtime.csv")
# LC <- read.csv("Pesticides/LC_buffers_overtime.csv")
# 
# pest$RTENO <- mapvalues(pest$BBS_route, from = match_file[,1], to = match_file[,2])
# LC$RTENO <- mapvalues(LC$BBS_route, from = match_file[,1], to = match_file[,2])
# 
# write.csv(pest, "Pesticides/pest_buff_overtime.csv", row.names = FALSE)
# write.csv(LC, "Pesticides/LC_buffers_overtime.csv", row.names = FALSE)


```

Do a similar analysis, but for circular buffers around butterfly site GPS locations.

```{r butterflies}

sites <- read.csv("C:/Users/Tyson/Desktop/Box Sync/Ohio/GIS/OHsites_reconciled.csv", header = TRUE)

###############
#2006 Landcover and pesticides by butterfly buffer
###############
#landcover raster
test.file <- "C:/Users/Tyson/Desktop/Clipped/Final clipped/lc2006.tif"
r <- raster(test.file)
#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

#counties shapefile
co.shp <- "oh_counties_plus"
OHco <- readOGR(dsn = "C:/Users/Tyson/Desktop/Clipped/Final clipped", layer = co.shp)
#OHco_p <- reproject(OHco, proj4string(r))
OHco_p <- spTransform(OHco, CRSobj = CRS(proj4string(r)))
OHco_p$GEOID <- as.numeric(as.character(OHco_p$GEOID))

#site coordinates
coordinates(sites) <- ~lon + lat
proj4string(sites) <- CRS("+init=epsg:4326")
sites_p <- spTransform(sites, CRSobj = CRS(proj4string(r)))

buff_200 <- gBuffer(sites_p, byid = TRUE, id = NULL, width = 200, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
buff_400 <- gBuffer(sites_p, byid = TRUE, id = NULL, width = 400, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
buff_1000 <- gBuffer(sites_p, byid = TRUE, id = NULL, width = 1000, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
buff_2000 <- gBuffer(sites_p, byid = TRUE, id = NULL, width = 2000, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
buff_5000 <- gBuffer(sites_p, byid = TRUE, id = NULL, width = 5000, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")
buff_10000 <- gBuffer(sites_p, byid = TRUE, id = NULL, width = 10000, quadsegs = 5, capStyle = "ROUND", joinStyle = "ROUND")

#This function extracts landcover for the county x bbs route intersections
#These can then by combined to get landcover by bbs route (with calculations of county-level pesticides added)

#ISSUE fixed: gIntersects/gIntersection use row.names as ID, but they start with 0!
ApportionLandcover <- function(counties, buffer, landcover){
  #find counties that intersect buffers, only use them for following analysis to speed things up
  bounds.sub <- gIntersects(counties, buffer, byid = TRUE)
  bounds.sub2 <- apply(bounds.sub, 2, function(x) {sum(x)})
  bounds.sub3 <- counties[which(bounds.sub2 > 0), ]
  
  #data.frame of intersections of buffers/counties
  int <- gIntersection(bounds.sub3, buffer, byid=TRUE) 
  intdf <- data.frame(intname=names(int))
  intdf$intname <- as.character(intdf$intname)
  splitid <- strsplit(intdf$intname, " ", fixed=TRUE) # split the names
  splitid <- do.call("rbind", splitid) # rbind those back together
  colnames(splitid) <- c("CountyRow", "SiteRow")
  intdf <- data.frame(intdf, splitid)
  intdf$CountyRow <- as.character(intdf$CountyRow)
  intdf$SiteRow <- as.character(intdf$SiteRow)
  
  library(snow)
  require(parallel)
  beginCluster( detectCores())
  
  lc <- extract(r, int)
  counts <- lapply(lc, table)
  out <- list(counts)
  
  endCluster()
  
 lc_out <- data.frame()
  for (j in 1:length(out[[1]])){
    temp <- out[[1]][[j]]
    temp.df <- data.frame(lc_class = names(unlist(temp)), pixels = as.numeric(unlist(temp)))
    temp.df$SiteRow <- intdf$SiteRow[j]
    temp.df$CountyRow <- intdf$CountyRow[j]
    lc_out <- rbind(lc_out, temp.df)
  }
    
 lc_out$GEOID <- mapvalues(lc_out$CountyRow, from = row.names(counties), to = counties$GEOID)
 lc_out$site <- mapvalues(lc_out$SiteRow, from = row.names(buffer), to = buffer$Name)
 return(lc_out)
}

buffers <- list(buff_200, buff_400, buff_1000, buff_2000, buff_5000, buff_10000)
buffer_LC2006 <- data.frame()
for (i in 1:length(buffers)) {
  temp <- ApportionLandcover(OHco_p, buffers[[i]], r)
  temp$buffer <- c(200, 400, 1000, 2000, 5000, 10000)[i]
  buffer_LC2006 <- rbind(buffer_LC2006, temp)
}
buffer_LC2006$year <- 2006
save(buffer_LC2006, file = "Landcover/bflybuff_LC2006.RData") 


###############
#2001 Landcover and pesticides by butterfly buffer
###############
#landcover raster
test.file <- "C:/Users/Tyson/Desktop/Clipped/Final clipped/lc2001.tif"
r <- raster(test.file)
#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

buffers <- list(buff_200, buff_400, buff_1000, buff_2000, buff_5000, buff_10000)
buffer_LC2001 <- data.frame()
for (i in 1:length(buffers)) {
  temp <- ApportionLandcover(OHco_p, buffers[[i]], r)
  temp$buffer <- c(200, 400, 1000, 2000, 5000, 10000)[i]
  buffer_LC2001 <- rbind(buffer_LC2001, temp)
}
buffer_LC2001$year <- 2001
save(buffer_LC2001, file = "Landcover/bflybuff_LC2001.RData") 


###############
#2011 Landcover and pesticides by butterfly buffer
###############
#landcover raster
test.file <- "C:/Users/Tyson/Desktop/Clipped/Final clipped/lc2011.tif"
r <- raster(test.file)
#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

buffers <- list(buff_200, buff_400, buff_1000, buff_2000, buff_5000, buff_10000)
buffer_LC2011 <- data.frame()
for (i in 1:length(buffers)) {
  temp <- ApportionLandcover(OHco_p, buffers[[i]], r)
  temp$buffer <- c(200, 400, 1000, 2000, 5000, 10000)[i]
  buffer_LC2011 <- rbind(buffer_LC2011, temp)
}

buffer_LC2011$year <- 2011
save(buffer_LC2011, file = "Landcover/bflybuff_LC2011.RData") 


###############
#1992/2001 Landcover change and pesticides by butterfly buffer
###############
#landcover raster
test.file <- "C:/Users/Tyson/Desktop/Clipped/Final clipped/lc_chg_9201.tif"
r <- raster(test.file)
#set CRS as Equal Albers Area projection
proj4string(r) <- CRS("+init=epsg:5070")

buffers <- list(buff_200, buff_400, buff_1000, buff_2000, buff_5000, buff_10000)
buffer_LC1992 <- data.frame()
for (i in 1:length(buffers)) {
  temp <- ApportionLandcover(OHco_p, buffers[[i]], r)
  temp$buffer <- c(200, 400, 1000, 2000, 5000, 10000)[i]
  buffer_LC1992 <- rbind(buffer_LC1992, temp)
}

buffer_LC1992$year <- 1992
save(buffer_LC1992, file = "Landcover/bflybuff_LC1992.RData") 

#Now reclassify landcover so all years use ALI codes 
load("Landcover/bflybuff_LC1992.RData")
load("Landcover/bflybuff_LC2011.RData") 
load("Landcover/bflybuff_LC2001.RData") 
load("Landcover/bflybuff_LC2006.RData") 

#translation table for 2001, 2006, 2011 ALII codes back to ALI codes
landclass <- data.frame(Value = c(0, 11, 21, 22, 23, 24, 31, 41, 42, 43, 52, 71, 81, 82, 90, 95), Class = c("NoData", "Water", "Urban", "Urban", "Urban", "Urban", "Barren", "Forest", "Forest", "Forest", "Grass", "Grass", "Agri", "Agri", "Wet", "Wet"), ALIcode = c(0, 1, 2, 2, 2, 2, 3, 4, 4, 4, 5, 5, 6, 6, 7, 7))

#these give Anderson Level I classes (total pixels) for each county
lc_buffer_2001 <- buffer_LC2001 %>% 
  mutate(reclass = mapvalues(lc_class, from = landclass$Value, to = landclass$ALIcode)) %>% 
  group_by(site, GEOID, buffer, reclass) %>% 
  summarise(total = sum(pixels)) %>% data.frame()

lc_buffer_2006 <- buffer_LC2006 %>% 
  mutate(reclass = mapvalues(lc_class, from = landclass$Value, to = landclass$ALIcode)) %>% 
  group_by(site, GEOID, buffer, reclass) %>% 
  summarise(total = sum(pixels)) %>% data.frame()

lc_buffer_2011 <- buffer_LC2011 %>% 
  mutate(reclass = mapvalues(lc_class, from = landclass$Value, to = landclass$ALIcode)) %>% 
  group_by(site, GEOID, buffer, reclass) %>% 
  summarise(total = sum(pixels)) %>% data.frame()


#make function to define 1992 and 2001 land cover from the NLCD change product
#it will be approximate
buffer_LC1992$reclass92 <- sapply(as.character(buffer_LC1992$lc_class), substring, 1, 1)
buffer_LC1992$reclass01 <- sapply(formatC(as.character(buffer_LC1992$lc_class), width = 2, format = "d", flag = "0"), substring, 2, 2)


#Estimate 1992 LC based on change from 2001 Landcover, instead of using 1992 estimates as the base
buffer_LC1992$lc_class <- as.numeric(as.character(buffer_LC1992$lc_class))
chg90s_1 <- buffer_LC1992 %>% filter(lc_class > 9) %>% group_by(site, GEOID, buffer, reclass92) %>% summarise(add_to_2001 = sum(pixels)) 
chg90s_2 <- buffer_LC1992 %>% filter(lc_class > 9) %>% group_by(site, GEOID, buffer, reclass01) %>% summarise(sub_from_2001 = sum(pixels))
names(chg90s_1)[4] <- "reclass"
names(chg90s_2)[4] <- "reclass"

chg90s <- merge(chg90s_1, chg90s_2, by = c("site", "GEOID", "buffer", "reclass"), all = TRUE)
chg90s_2001 <- merge(lc_buffer_2001, chg90s)
chg90s_2001$sub_from_2001 <- chg90s_2001$sub_from_2001 * -1
chg90s_2001$total_92est <- rowSums(chg90s_2001[, c("total", "add_to_2001", "sub_from_2001")], na.rm = TRUE)
lc_buffer_1992_backest <- chg90s_2001[, c("GEOID", "reclass", "site", "buffer", "total_92est")]
names(lc_buffer_1992_backest)[5] <- "total"
lc_buffer_1992_backest$year <- 1992


#bring all estimates together in one data frame
lc_buffer_2001$year <- 2001
lc_buffer_2006$year <- 2006
lc_buffer_2011$year <- 2011


#CONCLUSION
#Will use 1992 estimate of landcover based on 2001 values with 1992/2001 change product pixels
#the 1992 estimates based on 1992 classes are farther off
lc_all_buffers <- rbind(lc_buffer_1992_backest, lc_buffer_2001, lc_buffer_2006, lc_buffer_2011)
lc_all_buffers <- data.table(lc_all_buffers)


#expand lc_all so that all reclass values included, 0 if missing
uniqrow <- unique(lc_all_buffers[, list(GEOID, site, year)])
test <- CJ(unique(lc_all_buffers[,reclass]), unique(lc_all_buffers[,year]), unique(lc_all_buffers[, buffer]), sorted = FALSE)
setnames(test, "V1", "reclass")
setnames(test, "V2", "year")
setnames(test, "V3", "buffer")

test2 <- merge(uniqrow, test, by = "year", all = TRUE, allow.cartesian = TRUE)
test3 <- merge(lc_all_buffers, test2, by = c("reclass", "year", "GEOID", "site", "buffer"), all = TRUE)
test3$total[is.na(test3$total) == TRUE] <- 0

write.csv(test3, file = "Landcover/landcover_bflybuff.csv", row.names = FALSE)

LandcoverLine <- function(dat){
  yr <- data.frame(year = c(1992:2012))
  obs <- sort(dat$year)
      test <- data.frame()
      for (i in 1:(length(obs) - 1)){
        pix.seq <- seq(from = dat$total[dat$year == obs[i]], 
                       to = dat$total[dat$year == obs[i + 1]], 
                       len = (obs[i + 1] - obs[i] + 1))
        yr.seq <- seq(from = obs[i], to = obs[i+1])
        test <- rbind(test, data.frame(year = yr.seq, pix = pix.seq))
        }
      out <- test[-which(duplicated(test)), ]
      out <- merge(yr, out, all.x = TRUE)
      out$pix[out$year == 2012] <- out$pix[out$year == 2011] + (out$pix[out$year == 2011] - out$pix[out$year == 2010])
      return(out)
  }

DT <- fread("Landcover/landcover_bflybuff.csv")
DT[, buffer:=as.character(buffer)]
DT[, total:=as.numeric(total)]
DT[, year:=as.numeric(year)]

#find landcover class pixels over time for all buffer x county intersections
setkey(DT, GEOID, site)
lc_int_overtime <- DT[, LandcoverLine(data.frame(year = year, total = total)), by = list(site, GEOID, reclass, buffer)]
setnames(lc_int_overtime,"year","YEAR")
setkey(lc_int_overtime, site, YEAR)

# aggregate counties together into the buffers
lc_buff_overtime <- lc_int_overtime[, sum(pix, na.rm = TRUE), by = list(site, reclass, buffer, YEAR)]
setnames(lc_buff_overtime, "V1", "total_pix")
lc_buff_overtime[, km2 := total_pix * 0.0009]

Class = c("NoData", "Water", "Urban", "Barren", "Forest", "Grass", "Agri", "Wetlands")
ALIcode = as.character(c(0:7))

lc_buff_overtime %>% 
  mutate(landclass = mapvalues(reclass, from = ALIcode, to = Class))

write.csv(lc_buff_overtime, file = "Landcover/LC_bflybuff_overtime.csv", row.names = FALSE)


#join pesticides with above data.table to get pesticide use in counties, then aggregate by buffers
pest <- fread("Pesticides/estimated_pesticides_OHcounty_MOA.csv", header = TRUE)
setkey(pest, GEOID, YEAR)
pest[,pix := NULL]

lc.j <- lc_int_overtime[reclass == 6]
setkey(lc.j, GEOID, YEAR)
lc <- lc.j[pix > 0]

#fixing agri. pix problems here, total area of agri. in each buffer across counties
#this will be used to divide total pesticide use aggregated across county x buffer intersections
lc.fix <- lc %>%
  group_by(YEAR, site, buffer) %>%
  mutate(ag_km2_buffer = sum(pix) * 0.0009)

pest_buff <- merge(lc.fix, pest, allow.cartesian = TRUE)
pest_buff[, kg_buffGEOID_int := pix * 0.0009 * high_kg_km2ag] #kilograms of the pesticide group in buffer x county intersection

pest_buff1 <- pest_buff %>%
  group_by(YEAR, site, buffer, MOAuse, ag_km2_buffer) %>% #aggregates different counties into buffer that spans them
  summarise(kg_buff = sum(kg_buffGEOID_int)) %>%
  mutate(meanbuff_kgkm2ag = kg_buff / ag_km2_buffer)
  
write.csv(pest_buff1, "Pesticides/pest_bfly_buff_overtime_MOA.csv", row.names = FALSE)


#This sees if the buffer areas are consistent across years
#There is a gain of total pixels between the 90s and 2001, probably due to the NLCD products
#Should investigate this more, but percentages of LC over time are probably OK to use for now
test <- lc_buff_overtime %>%
  group_by(site, YEAR, buffer) %>%
  summarise(size = sum(total_pix, na.rm = TRUE)) %>%
  data.frame()



```


Does grouping by MOA make analysis more tractable?
Try PCA of pesticide use by MOA to see.
Still not a lot of variation explained :(

```{r}
#Do ordination on MOA pesticide data

pest <- fread("Pesticides/pest_bfly_buff_overtime_MOA.csv")

library(reshape2)
library(reshape)
library(vegan)

#choose buffer
pest <- pest[buffer == "5000"]

site_pest <- data.frame(cast(pest, site + YEAR ~ MOAuse, value = "meanbuff_kgkm2ag"))
site_pest[is.na(site_pest)] <- 0

site_pest[, -(1:2)] <- decostand(site_pest[, -(1:2)], 'standardize')
site_pest$site <- as.factor(site_pest$site)
site_pest$YEAR <- as.factor(site_pest$YEAR)

pca_pest <- princomp(site_pest[, -(1:2)], scale = FALSE)

test <- rda(site_pest[, -(1:2)] ~ site_pest$RTENO + site_pest$YEAR)


```





Pesticides/land-use/populations

Population estimates for ~40 species through time at different sites
Sites have seasonal environmental data (summer and winter PCA)
Site buffers have land-use and pesticide data over time (No PCA yet)

PLAN:
Ordinaton of buffer land-use
Ordination of top-used chemicals by buffer and year
Ordination of multiple species abundance estimates

Overlay all and see patterns?

Profit

```{r population analysis}
setwd("C:/Users/Tyson/REPO/NCEAS-RENCI_2014")


library(plyr)
library(dplyr)
library(reshape)
library(vegan)
library(ggplot2)


pest <- read.csv("Pesticides/pest_bfly_buff_overtime_MOA.csv", header = TRUE)
names(pest)[1:2] <- c("Year", "SiteID")
pest$SiteID <- as.character(pest$SiteID)

#extract landcover change trends for model, won't have yearly variation like pesticides or weather
#also might be good to classify sites with PCA for landcover context using landclass percentages
# lc <- read.csv("Landcover/LC_bflybuff_overtime.csv", header = TRUE)
# names(lc) <- c("SiteID", "reclass", "buffer", "Year", "total_pix", "km2")
# lc$reclass <- mapvalues(lc$reclass, from = c(1:7), to = c("water", "urban", "barren", "forest", "grass", "farm", "wetland"))
# lc$SiteID <- as.character(lc$SiteID)

BflyPops <- data.frame()
SpeciesList <- as.character(readRDS("C:/Users/Tyson/Desktop/Box Sync/Ohio/data2012/SpeciesList.rds")$CommonName)
SpeciesList[4] <- "Azures"
for (i in 1:40){
  sp <- SpeciesList[i]
  Pops <- readRDS(paste("C:/Users/Tyson/Desktop/Box Sync/Ohio/data2012/RDSfiles/popsites", sp, ".rds", sep = ""))
  Pops$Species <- sp
  BflyPops <- rbind(BflyPops, Pops)
}

BflyPops <- data.frame(BflyPops)
BflyPops$Year <- as.numeric(as.character(BflyPops$Year))
saveRDS(BflyPops, file = "BflyPops.rds")

#choose buffer
buffer <- 5000
# lc_subsample <- lc[lc$buffer == buffer, ]
pest_subsample <- pest[pest$buffer == buffer, ]
env <- merge(lc_subsample, pest_subsample, by = c("Year", "SiteID", "buffer"))

#remove pesticides not used much
pest_filt <- pest_subsample %>%
  group_by(MOAuse) %>%
  mutate(sumUse = sum(kg_buff)) %>%
  filter(sumUse > 1000)

# site_lc <- data.frame(cast(lc_subsample, SiteID + Year ~ reclass, value = "km2"))
# site_lc[is.na(site_lc)] <- 0

site_pest <- data.frame(cast(pest_filt, SiteID + Year ~ MOAuse, value = "meanbuff_kgkm2ag"))
site_pest[is.na(site_pest)] <- 0

# env <- merge(site_lc, site_pest, by = c("SiteID", "Year"), all.x = TRUE, all.y = FALSE)
env <- site_pest

spec_site_mat <- data.frame(cast(BflyPops, SiteID + Year ~ Species, value = "TrpzInd"))
spec_site_mat[is.na(spec_site_mat)] <- 0

env <- merge(spec_site_mat[, c(1:2)], env, by = c("SiteID", "Year"))
#NA's when buffers have no farmland => no estimated pesticide use
env[is.na(env)] <- 0

spec_site <- merge(env[, c(1:2)], spec_site_mat, by = c("SiteID", "Year"))

#scale land use so total in each buffer (row) sum to 1
#scale pesticides by column, standardize?
# env[, 3:9] <- decostand(env[, 3:9], 'total')
# env[, 10:17] <- decostand(env[, 10:17], 'standardize')
env[, 3:22] <- decostand(env[, 3:22], 'standardize')
env$SiteID <- as.factor(env$SiteID)
env$Year <- as.factor(env$Year)

spec_site_hell <- decostand(spec_site[, -c(1:2)], 'hell')
spec_site_wisc <- wisconsin(spec_site[, -c(1:2)])

#trying out different unconstrained and constrained rdas
test <- rda(spec_site_hell)
test <- rda(spec_site_hell ~ ., env[,c(3:22)])
test <- rda(spec_site_hell ~ env[,2])

#try out site and year as factors in species ordination
#repeated below using adonis function instead
test <- rda(spec_site_hell ~ factor(env$SiteID) + factor(env$Year))

(r2 <- RsquareAdj(test)$r.squared)
(r2adj <- RsquareAdj(test)$adj.r.squared)

#Make some ordination plots of spatial and temporal variation in environmental variables.
plot(test, scaling = 2)
spe.sc <- scores(test, choices = 1:2, display = "sp")
arrows(0,0, spe.sc[,1], spe.sc[,2], length = 0, lty = 1, col = "red")

#PERMANOVA shows that much more butterfly variation over sites than between years (when looking at entire state)
#This may not actually say much about yearly variation at a particular site, though.
ado <- adonis(spec_site[3:42] ~ as.factor(SiteID) + as.factor(Year), data = spec_site, permutations = 999,
              method = "bray")

ado <- adonis(spec_site[3:42] ~ as.factor(Year), data = spec_site, strata = spec_site$SiteID, permutations = 999,
              method = "bray")
ado <- adonis(spec_site[3:42] ~ as.factor(SiteID), data = spec_site, strata = spec_site$Year, permutations = 999,
              method = "bray")


#How much does pesticide use vary over time and space?
ado <- adonis(env[, 3:31] ~ as.factor(Year), data = env, strata = env$SiteID, permutations = 999,
              method = "euclidean")
ado <- adonis(env[,3:31] ~ as.factor(SiteID), data = env, strata = env$Year, permutations = 999,
              method = "euclidean")

#Trying to figure out a way to plot means/SEs of groups (like sites or years)

dis <- vegdist(spec_site[3:42])
#landcover dissimilarity
dis <- vegdist(env[, 3:9], method = "euclidean")

years <- as.factor(spec_site$Year)
sites <- as.factor(spec_site$SiteID)

mod <- betadisper(dis, sites, type = "centroid")
plot(mod)
ordiellipse(mod, sites)

pcoa<- cmdscale(dis)
# plot them with different symbols for groups
pcoa <- as.data.frame(pcoa)
pcoa$year <- spec_site$Year
pcoa$site <- spec_site$SiteID

yrs <- pcoa %>% 
  group_by(year) %>%
  summarise(meanV1 = mean(V1), meanV2 = mean(V2), sdV1 = sd(V1), sdV2 = sd(V2))

p <- ggplot(yrs, aes(x = meanV1, y = meanV2, colour = year))
p + geom_point(aes(size = 3)) + geom_errorbar(aes(ymax = meanV2 + sdV2, ymin = meanV2 - sdV2)) +
  geom_errorbarh(aes(xmax = meanV1 + sdV1, xmin = meanV1 - sdV1))


sites <- pcoa %>% 
  group_by(site) %>%
  summarise(meanV1 = mean(V1), meanV2 = mean(V2), sdV1 = sd(V1), sdV2 = sd(V2))
q <- ggplot(sites, aes(x = meanV1, y = meanV2, colour = site))
q + geom_point(aes(size = 3)) + geom_errorbar(aes(ymax = meanV2 + sdV2, ymin = meanV2 - sdV2)) +
  geom_errorbarh(aes(xmax = meanV1 + sdV1, xmin = meanV1 - sdV1))



# partial mantel test of pesticide effects while controlling for land use
pest.pc <- prcomp(env[10:17], scale = FALSE)
pc <- scores(pest.pc, display = "sites", choices = 1:4)
  pest.dis <- vegdist(pc, method = "euclid")

lc.pc <- prcomp(env[3:9], scale = TRUE)
pc <- scores(lc.pc, display = "sites", choices = 1:4)
lc.dis <- vegdist(pc, method = "euclid")

  bflydis <- vegdist(spec_site_hell)
  man <- mantel.partial(bflydis, pest.dis, lc.dis)
```







